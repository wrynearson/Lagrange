---
title: Thesis Data
date: 2021-03-14
tags: [Water]
description: My thesis data, exported from a jupyter notebook
image: "output_76_0.png"
layout: post
excerpt_separator: <!--more-->
author: Will Rynearson
---

# Water Quality, Perception and Knowledge in China: *Data Analysis (condensed)*

This document is the data analysis of water quality, water quality perception, and water quality knowledge in China. The analysis is driven primarily by two datasets - water quality (2017, per prefecture) and a national general social survey (China General Social Survey, 2010) with an environmental module.

## Research Questions and Hypotheses

| Question Number | Research Question                                                                                                       | H0 (Null Hypothesis)                                                       | H1 (Hypothesis)                                                                                                            |
|:---------------:|:-----------------------------------------------------------------------------------------------------------------------:|:--------------------------------------------------------------------------:|:--------------------------------------------------------------------------------------------------------------------------:|
| R1              | Is there a relationship between water quality and perception of water quality? (I.e. do perceptions and reality match)? | Worse local water quality is independent of water quality perception.      | Worse local (provincial) water quality relates to an increased perception of severity of water quality issues (`l14d`→ 1). |
| R2              | Does knowledge of water quality affect perception?                                                                      | Increased knowledge is independent of perception.                          | An increase knowledge of water quality issues relates to an increased perception of severity.                              |
| R3              | Does the level of obtained education relate to water quality knowledge?                                                 | Increased education is independent of knowledge of water quality.          | Increased education relates to more knowledge about water quality.                                                         |
| R4              | Does the level of obtained education relate perception?                                                                 | Increased education is independent of an increased perception of severity. | Increased education relates to an increased perception of severity                                                         |
| R5              | Are there differences between water quality perception, and water quality knowledge, in rural vs. urban households?     | There is no significant difference between urban and rural households.     | There is a significant difference in perception of severity of water quality issues between urban and rural households.    |
| R6              | Is there a relationship between water quality and knowledge of water quality?                                           | There is no relation between water quality and water quality knowledge.    | There is a relation between water quality and water quality knowledge.                                                     |

## Core Analyzed Data

| Code  | English                                                                                                                                           | Chinese                                                          | Value Range (used)                           |
|:-------:|---------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------|----------------------------------------------|
| s41   | Province                                                                                                                                          | 省                                                                | Range, *see data analysis*                   |
| a2    | Gender                                                                                                                                            | 性别                                                               | 1 = male, 2 = female                         |
| a3a   | Birth year                                                                                                                                        | 您的出生日期是什么                                                        | Birth year                                   |
| a7a   | Highest level of obtained education                                                                                                               | 您目前的最高教育程度是                                                      | 1 = none, 13 = master's and above            |
| a91   | Rural / agricultural household                                                                                                                    | 请问目前您或者您配偶是否为农业户口(或者户口所在地为农村),且在农村(包括家乡和其它地方)有承包的旱地、水田、山林、水面等土地? | 1 = yes, 2 = no                              |
| l14d  | "How do you think the pollution of rivers, rivers and lakes in China is harmful to the environment?" (*Used to measure perception*)               | 您认为中国的江、河、湖泊的污染对环境的危害程度是?                                        | 1 = very important, 5 = not important at all |
| l2409 | "In the domestic water pollution report, the water quality of Category V (5) is better than that of Category I (1)" (*Used to measure knowledge, response==2 is correct*) | 国内水体污染报告中,V(5)类水质要比I(1)类水质好                                      | 1 = correct, **2 = incorrect**               |


More information about the thesis, motivation, and methodology is located in the main "thesis_analysis.ipynb" document.

## Load Data

Load Python libraries


```python
import pandas as pd
from pandas import DataFrame
import numpy as np # for some regression visualizations
import matplotlib as mpl
import matplotlib.pyplot as plt # for some visualizations
import seaborn as sns # for plots
import statsmodels.api as sm # for statistical analysis
import statsmodels.formula.api as smf # for statistical analysis
from sklearn import preprocessing # for normalizing data
import pingouin as pi # for statistical analysis
```


```python
# Returns ALL columns when displaying DataFrame, useful for finding column names
pd.set_option('display.max_columns', None)
```


```python
# Set the standard theme for plots
sns.set_theme(
    # palette='twilight'
    )
sns.set_style("ticks")
```

Load CGSS (social survey) data from a Stata file


```python
cgss = pd.read_stata('../data/cgss2010_12.dta', preserve_dtypes = True, convert_categoricals=False)
```

List categorical data


```python
categoricals = ["s41","a2","a91","l1a","l1b","l7a","l7b","l2409"]
```

List important questions


```python
important = ['score','s41','a2','a3a','a7a','a8a','a91','l1a','l1b','l6a','l6b','l7a','l7b','l8a','l8b','l137','l14d','l15a','l15b','l16c','l20e','l2409','province','province_en']
```

List utilized important demographic data


```python
demographic = ['s41','a2','a3a','a7a','a91']
```

List utilized important environmental data


```python
environmental = ['s41','province','province_en','score','l1a','l1b','l6a','l6b','l7a','l7b','l8a','l8b','l14d','l2409']
```

Convert categorical data into categorical data types


```python
cgss[categoricals].astype('category')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>s41</th>
      <th>a2</th>
      <th>a91</th>
      <th>l1a</th>
      <th>l1b</th>
      <th>l7a</th>
      <th>l7b</th>
      <th>l2409</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>28.0</td>
      <td>2</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>28.0</td>
      <td>2</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>28.0</td>
      <td>2</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>28.0</td>
      <td>2</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>98.0</td>
      <td>98.0</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>28.0</td>
      <td>1</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>11778</th>
      <td>1.0</td>
      <td>1</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>11779</th>
      <td>1.0</td>
      <td>1</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>11780</th>
      <td>1.0</td>
      <td>1</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>11781</th>
      <td>1.0</td>
      <td>1</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>10.0</td>
      <td>98.0</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>11782</th>
      <td>1.0</td>
      <td>1</td>
      <td>2.0</td>
      <td>9.0</td>
      <td>9.0</td>
      <td>10.0</td>
      <td>2.0</td>
      <td>2.0</td>
    </tr>
  </tbody>
</table>
<p>11783 rows × 8 columns</p>
</div>



Load province data from a .csv, set province code as the index


```python
provinces = pd.read_csv('prov.csv')
```

Load water quality data


```python
wqir = pd.read_csv('../data/wqir2018_zh.csv', sep=' ', encoding = "UTF-8")
```

---

## Merge data into one dataframe

Group the water quality data (WQIR) by province and compute the mean


```python
wqir_mean = wqir.groupby(by='province').agg('mean')
```

Merge the mean water quality per province and the province dataframe (matching names and province codes)


```python
merge = pd.merge(wqir_mean, provinces, on='province')
```

Drop rank column, merge the previously merged column into the main cgss dataframe so that each entry has the mean water score from their province, plus the names of their province (Chinese short and full and English).


```python
wq = merge[['s41','score','province','province_full','province_en']]
cgss_wq_full = pd.merge(cgss,wq,on='s41')
```

Only analyze important questions and variables (drop remaining ones)


```python
cgss_wq = cgss_wq_full[important]
```

---

## Testing Hypotheses (Descriptive Analysis)

### H1 - Worse local (provincial) water quality (`score` increases) relates to an increased perception of severity of water quality issues (`l14d` decreases).

First, clean the data for `l14d` by dropping NaN, negative and "cannot answer" values:


```python
cgss_wq_l14d = cgss_wq[cgss_wq["l14d"]>0]
cgss_wq_l14d = cgss_wq_l14d[cgss_wq_l14d["l14d"]<6]
```

Visualize the results: Perception vs. Water Quality (more details about sns.lmplot in the Hypothesis 4 section)


```python
h1_fig1 = sns.lmplot(
    data=cgss_wq_l14d,
    x = 'l14d',
    y = 'score',
    x_estimator=np.mean,
    )
h1_fig1.savefig('outputs/h1_fig1.svg')
```


​    
![png](output_43_0.png)
​    



```python
pi.corr(x=cgss_wq_l14d['score'], y=cgss_wq_l14d['l14d'])
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n</th>
      <th>r</th>
      <th>CI95%</th>
      <th>r2</th>
      <th>adj_r2</th>
      <th>p-val</th>
      <th>BF10</th>
      <th>power</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>pearson</th>
      <td>3253</td>
      <td>-0.1023</td>
      <td>[-0.14, -0.07]</td>
      <td>0.010465</td>
      <td>0.009856</td>
      <td>4.980902e-09</td>
      <td>5.811e+05</td>
      <td>0.999951</td>
    </tr>
  </tbody>
</table>
</div>



#### Initial findings:
- While the correlation is significant (Low $p$ value == more compelled to reject null hypothesis), there is a poor regression fit (low r²)
- Multivariable analysis required for further investigation

### H2 - An increase knowledge of water quality issues (`l2409`) relates to an increased perception of severity (`l14d`).

Clean data for `l2409` using previously cleaned `l14d` dataframe:
**NOTE**: Only keeping binary responses (dropping *Can't respond* value `8`)


```python
cgss_wq_l14d_l2409 = cgss_wq_l14d[cgss_wq_l14d["l2409"]>0]
cgss_wq_l14d_l2409 = cgss_wq_l14d_l2409[cgss_wq_l14d_l2409["l2409"]<3]
```


```python
h2 = cgss_wq_l14d_l2409.groupby('l2409').agg('mean')
h2
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>score</th>
      <th>s41</th>
      <th>a2</th>
      <th>a3a</th>
      <th>a7a</th>
      <th>a8a</th>
      <th>a91</th>
      <th>l1a</th>
      <th>l1b</th>
      <th>l6a</th>
      <th>l6b</th>
      <th>l7a</th>
      <th>l7b</th>
      <th>l8a</th>
      <th>l8b</th>
      <th>l137</th>
      <th>l14d</th>
      <th>l15a</th>
      <th>l15b</th>
      <th>l16c</th>
      <th>l20e</th>
    </tr>
    <tr>
      <th>l2409</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1.0</th>
      <td>16.223121</td>
      <td>16.046099</td>
      <td>1.482270</td>
      <td>1964.570922</td>
      <td>5.109929</td>
      <td>1258061.250</td>
      <td>1.576512</td>
      <td>6.521277</td>
      <td>6.414894</td>
      <td>3.833333</td>
      <td>2.414894</td>
      <td>7.414894</td>
      <td>6.581560</td>
      <td>2.836879</td>
      <td>2.521277</td>
      <td>3.567376</td>
      <td>2.382979</td>
      <td>2.471631</td>
      <td>2.297872</td>
      <td>2.769504</td>
      <td>2.329787</td>
    </tr>
    <tr>
      <th>2.0</th>
      <td>16.891944</td>
      <td>15.031088</td>
      <td>1.452504</td>
      <td>1965.616580</td>
      <td>6.341969</td>
      <td>1422613.875</td>
      <td>1.704663</td>
      <td>5.155440</td>
      <td>6.892919</td>
      <td>3.827288</td>
      <td>2.018998</td>
      <td>7.652850</td>
      <td>8.120898</td>
      <td>3.138169</td>
      <td>2.737478</td>
      <td>3.854922</td>
      <td>2.186528</td>
      <td>2.485320</td>
      <td>2.412781</td>
      <td>2.892919</td>
      <td>2.307427</td>
    </tr>
  </tbody>
</table>
</div>



Count the number of responses per `l2409`


```python
cgss_wq_l14d_l2409["l2409"].value_counts()
```




    2.0    579
    1.0    282
    Name: l2409, dtype: int64



Now, plot: (`l2409==2` is the correct answer)


```python
h2_fig1 = sns.catplot(
    data=cgss_wq_l14d_l2409,
    x = 'l2409',
    y = 'l14d',
    hue='a91',
    split=True,
    kind='violin',
    scale='count',
    )
h2_fig1.savefig('outputs/h2_fig1.svg')
```


​    
![png](output_53_0.png)
​    


Plot again - note that the line connecting the two isn't relevant or accurate


```python
sns.catplot(
    data=cgss_wq_l14d_l2409,
    x = 'l2409',
    y = 'l14d',
    kind='point',
    #hue='a91',
    )
```




    <seaborn.axisgrid.FacetGrid at 0x7fb62a35b790>




​    
![png](output_55_1.png)
​    



```python
pi.corr(x=cgss_wq_l14d_l2409['l2409'], y=cgss_wq_l14d_l2409['l14d'], method='kendall')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n</th>
      <th>r</th>
      <th>CI95%</th>
      <th>r2</th>
      <th>adj_r2</th>
      <th>p-val</th>
      <th>power</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>kendall</th>
      <td>861</td>
      <td>-0.10499</td>
      <td>[-0.17, -0.04]</td>
      <td>0.011023</td>
      <td>0.008718</td>
      <td>0.000906</td>
      <td>0.870417</td>
    </tr>
  </tbody>
</table>
</div>



#### Initial findings:
- Increased water quality knowledge `l2409==2` has an increased perception (decreased `l14d`).
    - Statistically significant ($p<=0.05$) but weakly correlated ($0<r<.19$)
- However, this trend is no longer visible when factoring for rural/urban `a91`, education level `a7a`, etc
- Other large differences between rural/non-rural exist (see `h2` above)
- More analysis is needed

### H3 - Increased education (`a7a`) relates to more knowledge about water quality (`l2409`).


Clean data for `l2409`

Again, **NOTE**: Only keeping binary responses (dropping "*Can't respond*" value `8`)


```python
cgss_wq_l2409 = cgss_wq[cgss_wq["l2409"]>0]
cgss_wq_l2409 = cgss_wq_l2409[cgss_wq_l2409["l2409"]<3]
```

Now, clean for education `a7a`


```python
cgss_wq_l2409_a7a = cgss_wq_l2409[cgss_wq_l2409["a7a"]>=0]
cgss_wq_l2409_a7a = cgss_wq_l2409_a7a[cgss_wq_l2409_a7a["a7a"]<14]
```

Now, plot:


```python
h3_fig1 = sns.lmplot(
    data=cgss_wq_l2409_a7a,
    x = 'a7a',
    y = 'l2409',
    x_estimator=np.mean,
    )
h3_fig1.savefig('outputs/h3_fig1.svg')
```


​    
![png](output_64_0.png)
​    



```python
h3_fig2 = sns.catplot(
    data=cgss_wq_l2409_a7a,
    x = 'l2409',
    y = 'a7a',
    hue='a91',
    split=True,
    kind='violin',
    scale='count',
    )
h3_fig2.savefig('outputs/h3_fig2.svg')
```


​    
![png](output_65_0.png)
​    



```python
pi.corr(x=cgss_wq_l2409_a7a['l2409'], y=cgss_wq_l2409_a7a['a7a'], method='spearman')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n</th>
      <th>r</th>
      <th>CI95%</th>
      <th>r2</th>
      <th>adj_r2</th>
      <th>p-val</th>
      <th>power</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>spearman</th>
      <td>881</td>
      <td>0.163802</td>
      <td>[0.1, 0.23]</td>
      <td>0.026831</td>
      <td>0.024614</td>
      <td>0.000001</td>
      <td>0.998361</td>
    </tr>
  </tbody>
</table>
</div>



#### Initial findings
- There seems to be a slight trend (education increase relates to knowledge increase)
- The violin plots show differences in rural vs non-rural responses
- More analysis is needed

## H4 - Increased education `a7a` relates to an increased perception of severity `l14d`

First, see the distribution of education:


```python
cgss_wq[["a7a","l14d"]].hist()
```




    array([[<AxesSubplot:title={'center':'a7a'}>,
            <AxesSubplot:title={'center':'l14d'}>]], dtype=object)




​    
![png](output_70_1.png)
​    


Make new cleaned dataset with cleaned `a7a` values from the previously cleaned `l14d` values


```python
cgss_wq_l14d_a7a = cgss_wq_l14d[cgss_wq_l14d['a7a']>=0]
```

Group by each education level (year) and aggregate the mean


```python
h4 = cgss_wq_l14d_a7a.groupby('a7a').agg('mean')
```

Plot result (perception vs. education level). 

**Note**: Since `a7a` is the index of h4, it needs to be reset before being plotted in regplot (info [here](https://www.reddit.com/r/learnpython/comments/3cjnpg/seaborn_xaxis_as_index/))


```python
h4_fig1 = sns.lmplot(
    data=h4.reset_index(),
    x = 'a7a',
    y = 'l14d'
    )
h4_fig1.savefig('outputs/h4_fig1.svg')
```


​    
![png](output_76_0.png)
​    


It's better (?) to use an lmplot (similar to regplot) and calculate the mean per x bin, from [here](https://seaborn.pydata.org/tutorial/regression.html).
> A second option is to collapse over the observations in each discrete bin to plot an estimate of central tendency along with a confidence interval:

Additionally, the lmplot allows for multiple regressions to be plotted on the same plot.


```python
h4_fig2 = sns.lmplot(
    data=cgss_wq_l14d_a7a,
    x = 'a7a',
    y = 'l14d',
    x_estimator=np.mean,
    hue='a91',
    markers=(["o", "x"]),
    )
h4_fig2.savefig('outputs/h4_fig2.svg')
```


​    
![png](output_78_0.png)
​    



```python
pi.corr(x=cgss_wq_l14d_a7a['a7a'], y=cgss_wq_l14d_a7a['l14d'])
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n</th>
      <th>r</th>
      <th>CI95%</th>
      <th>r2</th>
      <th>adj_r2</th>
      <th>p-val</th>
      <th>BF10</th>
      <th>power</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>pearson</th>
      <td>3252</td>
      <td>-0.210865</td>
      <td>[-0.24, -0.18]</td>
      <td>0.044464</td>
      <td>0.043876</td>
      <td>5.256292e-34</td>
      <td>2.634e+30</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>



### Initial findings:
- There is a clear trend between education and perception
- Rural households have a higher `l14d` than non-rural at each education level
    - This difference decreases as education increases

### H5 - There is a significant difference in perception of severity of water quality issues (`l14d`) between urban and rural households (`a91`).

Reuse the cleaned data from `H1` for question `l14d`, see number of responses by type by grouping by `a91`, where a91==1 is rural


```python
cgss_wq_l14d[['a91','l14d']].groupby('a91').agg('count')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>l14d</th>
    </tr>
    <tr>
      <th>a91</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1.0</th>
      <td>1257</td>
    </tr>
    <tr>
      <th>2.0</th>
      <td>1995</td>
    </tr>
  </tbody>
</table>
</div>



Calculate the mean `l14d` grouped by rural / urban


```python
h5 = cgss_wq_l14d.groupby('a91').agg('mean')
h5.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>score</th>
      <th>s41</th>
      <th>a2</th>
      <th>a3a</th>
      <th>a7a</th>
      <th>a8a</th>
      <th>l1a</th>
      <th>l1b</th>
      <th>l6a</th>
      <th>l6b</th>
      <th>l7a</th>
      <th>l7b</th>
      <th>l8a</th>
      <th>l8b</th>
      <th>l137</th>
      <th>l14d</th>
      <th>l15a</th>
      <th>l15b</th>
      <th>l16c</th>
      <th>l20e</th>
      <th>l2409</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000e+00</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>16.544259</td>
      <td>15.638292</td>
      <td>1.516332</td>
      <td>1963.058528</td>
      <td>4.859155</td>
      <td>1.336766e+06</td>
      <td>8.288372</td>
      <td>9.239028</td>
      <td>3.716190</td>
      <td>2.433684</td>
      <td>10.954489</td>
      <td>10.937637</td>
      <td>2.868745</td>
      <td>2.527442</td>
      <td>3.742055</td>
      <td>2.354314</td>
      <td>3.036047</td>
      <td>3.006931</td>
      <td>3.283117</td>
      <td>2.489414</td>
      <td>6.239900</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.729610</td>
      <td>1.787362</td>
      <td>0.011284</td>
      <td>0.744155</td>
      <td>1.950825</td>
      <td>4.038638e+05</td>
      <td>1.285412</td>
      <td>1.589209</td>
      <td>0.139791</td>
      <td>0.399241</td>
      <td>2.420259</td>
      <td>1.801677</td>
      <td>0.223903</td>
      <td>0.177754</td>
      <td>0.141492</td>
      <td>0.257222</td>
      <td>0.121157</td>
      <td>0.160084</td>
      <td>0.260029</td>
      <td>0.254049</td>
      <td>0.167012</td>
    </tr>
    <tr>
      <th>min</th>
      <td>16.028347</td>
      <td>14.374436</td>
      <td>1.508353</td>
      <td>1962.532331</td>
      <td>3.479714</td>
      <td>1.051192e+06</td>
      <td>7.379449</td>
      <td>8.115288</td>
      <td>3.617343</td>
      <td>2.151378</td>
      <td>9.243108</td>
      <td>9.663659</td>
      <td>2.710422</td>
      <td>2.401750</td>
      <td>3.642005</td>
      <td>2.172431</td>
      <td>2.950376</td>
      <td>2.893734</td>
      <td>3.099248</td>
      <td>2.309774</td>
      <td>6.121805</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>16.286303</td>
      <td>15.006364</td>
      <td>1.512343</td>
      <td>1962.795430</td>
      <td>4.169434</td>
      <td>1.193979e+06</td>
      <td>7.833910</td>
      <td>8.677158</td>
      <td>3.666767</td>
      <td>2.292531</td>
      <td>10.098799</td>
      <td>10.300648</td>
      <td>2.789583</td>
      <td>2.464596</td>
      <td>3.692030</td>
      <td>2.263373</td>
      <td>2.993212</td>
      <td>2.950333</td>
      <td>3.191182</td>
      <td>2.399594</td>
      <td>6.180852</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>16.544259</td>
      <td>15.638292</td>
      <td>1.516332</td>
      <td>1963.058528</td>
      <td>4.859155</td>
      <td>1.336766e+06</td>
      <td>8.288372</td>
      <td>9.239028</td>
      <td>3.716190</td>
      <td>2.433684</td>
      <td>10.954489</td>
      <td>10.937637</td>
      <td>2.868745</td>
      <td>2.527442</td>
      <td>3.742055</td>
      <td>2.354314</td>
      <td>3.036047</td>
      <td>3.006931</td>
      <td>3.283117</td>
      <td>2.489414</td>
      <td>6.239900</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>16.802215</td>
      <td>16.270220</td>
      <td>1.520321</td>
      <td>1963.321627</td>
      <td>5.548876</td>
      <td>1.479554e+06</td>
      <td>8.742834</td>
      <td>9.800898</td>
      <td>3.765614</td>
      <td>2.574837</td>
      <td>11.810180</td>
      <td>11.574626</td>
      <td>2.947906</td>
      <td>2.590287</td>
      <td>3.792080</td>
      <td>2.445256</td>
      <td>3.078883</td>
      <td>3.063529</td>
      <td>3.375051</td>
      <td>2.579234</td>
      <td>6.298948</td>
    </tr>
    <tr>
      <th>max</th>
      <td>17.060171</td>
      <td>16.902147</td>
      <td>1.524311</td>
      <td>1963.584726</td>
      <td>6.238596</td>
      <td>1.622341e+06</td>
      <td>9.197295</td>
      <td>10.362768</td>
      <td>3.815038</td>
      <td>2.715990</td>
      <td>12.665871</td>
      <td>12.211615</td>
      <td>3.027068</td>
      <td>2.653133</td>
      <td>3.842105</td>
      <td>2.536197</td>
      <td>3.121718</td>
      <td>3.120127</td>
      <td>3.466985</td>
      <td>2.669053</td>
      <td>6.357995</td>
    </tr>
  </tbody>
</table>
</div>




```python
pi.corr(x=cgss_wq_l14d['a91'], y=cgss_wq_l14d['l14d'], method='spearman')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n</th>
      <th>r</th>
      <th>CI95%</th>
      <th>r2</th>
      <th>adj_r2</th>
      <th>p-val</th>
      <th>power</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>spearman</th>
      <td>3252</td>
      <td>-0.201821</td>
      <td>[-0.23, -0.17]</td>
      <td>0.040732</td>
      <td>0.040141</td>
      <td>3.094507e-31</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>



#### Initial findings: 
- There is a difference between rural and urban households (rural have less severe perception of water quality)
- Education level (`a7a`) is significantly different between urban and rural households

### H6 - There is a relation between water quality `score` and water quality knowledge `l2409`.

Drop negative values, keep `l2409` == 8 this time ("*Can't answer*")


```python
cgss_wq_score_l2409_8 = cgss_wq[cgss_wq['l2409'].isin([1,2,8])]
```


```python
cgss_wq_score_l2409_8.groupby('l2409').agg('mean')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>score</th>
      <th>s41</th>
      <th>a2</th>
      <th>a3a</th>
      <th>a7a</th>
      <th>a8a</th>
      <th>a91</th>
      <th>l1a</th>
      <th>l1b</th>
      <th>l6a</th>
      <th>l6b</th>
      <th>l7a</th>
      <th>l7b</th>
      <th>l8a</th>
      <th>l8b</th>
      <th>l137</th>
      <th>l14d</th>
      <th>l15a</th>
      <th>l15b</th>
      <th>l16c</th>
      <th>l20e</th>
    </tr>
    <tr>
      <th>l2409</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1.0</th>
      <td>16.197448</td>
      <td>16.101046</td>
      <td>1.484321</td>
      <td>1964.585366</td>
      <td>5.083624</td>
      <td>1271105.5</td>
      <td>1.580420</td>
      <td>6.787456</td>
      <td>6.672474</td>
      <td>3.825784</td>
      <td>2.404181</td>
      <td>7.668990</td>
      <td>6.554007</td>
      <td>2.815331</td>
      <td>2.491289</td>
      <td>3.547038</td>
      <td>2.442509</td>
      <td>2.459930</td>
      <td>2.296167</td>
      <td>2.766551</td>
      <td>2.324042</td>
    </tr>
    <tr>
      <th>2.0</th>
      <td>16.846471</td>
      <td>15.040269</td>
      <td>1.451342</td>
      <td>1965.412752</td>
      <td>6.298658</td>
      <td>1415841.5</td>
      <td>1.699664</td>
      <td>5.261745</td>
      <td>6.939597</td>
      <td>3.825503</td>
      <td>2.036913</td>
      <td>8.015101</td>
      <td>8.468121</td>
      <td>3.132550</td>
      <td>2.729866</td>
      <td>3.860738</td>
      <td>2.352349</td>
      <td>2.484899</td>
      <td>2.406040</td>
      <td>2.901007</td>
      <td>2.315436</td>
    </tr>
    <tr>
      <th>8.0</th>
      <td>16.560695</td>
      <td>15.326776</td>
      <td>1.546448</td>
      <td>1961.880146</td>
      <td>4.699454</td>
      <td>1446802.5</td>
      <td>1.574135</td>
      <td>10.890710</td>
      <td>12.264117</td>
      <td>3.697268</td>
      <td>2.723133</td>
      <td>16.091803</td>
      <td>15.110747</td>
      <td>2.887796</td>
      <td>2.560656</td>
      <td>3.877960</td>
      <td>3.103825</td>
      <td>3.472495</td>
      <td>3.459381</td>
      <td>3.671767</td>
      <td>2.550091</td>
    </tr>
  </tbody>
</table>
</div>




```python
h6_fig1 = sns.catplot(
    data=cgss_wq[~cgss_wq['l2409'].isin([-3,-2])],
    y = 'l2409',
    x = 'score',
    # hue='a91',
    #split=True,
    kind='boxen',
    # scale='mean',
    orient='h',
    )
h6_fig1.savefig('outputs/h6_fig1.svg')
```


​    
![png](output_92_0.png)
​    



```python
pi.corr(x=cgss_wq_score_l2409_8['score'], y=cgss_wq_score_l2409_8['l14d'], method='kendall')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n</th>
      <th>r</th>
      <th>CI95%</th>
      <th>r2</th>
      <th>adj_r2</th>
      <th>p-val</th>
      <th>power</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>kendall</th>
      <td>3628</td>
      <td>-0.095982</td>
      <td>[-0.13, -0.06]</td>
      <td>0.009213</td>
      <td>0.008666</td>
      <td>2.450049e-14</td>
      <td>0.999938</td>
    </tr>
  </tbody>
</table>
</div>



---

<div class="alert alert-block alert-info">
<b>Note:</b> Sections below are not final. Work in progress (March 11th, 2021).</div>

---

## Additional descriptive analysis

### `l6`
Start with `l6`, where:
- `l6a` asks "Generally speaking, how much do you care about environmental issues?
- `l6b` asks "Based on your own judgment, on the whole, do you think the environmental problems facing China are serious?"

First, clean data: (**Note**: When I tried this in one step (two columns), I was having graph issues later, so I did each step individually)


```python
cgss_wq_l6 = cgss_wq[cgss_wq['l6a']>0]
cgss_wq_l6 = cgss_wq_l6[cgss_wq_l6['l6a']<6]
cgss_wq_l6 = cgss_wq_l6[cgss_wq_l6['l6b']>0]
cgss_wq_l6 = cgss_wq_l6[cgss_wq_l6['l6b']<6]
```

Plot


```python
fig, ax = plt.subplots()
cgss_wq_l6.hist(['l6a','l6b'], ax=ax)
fig.savefig('outputs/l6_fig1.svg')
```

    <ipython-input-44-28fbaadde786>:2: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared
      cgss_wq_l6.hist(['l6a','l6b'], ax=ax)




![png](output_102_1.png)
    



```python
l6_fig2 = sns.lmplot(
    data=cgss_wq_l6,
    x = 'l6a',
    y = 'l6b',
    x_estimator=np.mean,
    hue='a91'
    )
l6_fig2.savefig('outputs/l6_fig2.svg')
```


​    
![png](output_103_0.png)
​    



```python
pi.corr(x=cgss_wq_l6['l6a'], y=cgss_wq_l6['l6b'])
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n</th>
      <th>r</th>
      <th>CI95%</th>
      <th>r2</th>
      <th>adj_r2</th>
      <th>p-val</th>
      <th>BF10</th>
      <th>power</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>pearson</th>
      <td>3362</td>
      <td>-0.272594</td>
      <td>[-0.3, -0.24]</td>
      <td>0.074307</td>
      <td>0.073756</td>
      <td>2.322155e-58</td>
      <td>4.335e+54</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>



### `l7`

Compare with `l7` ("Which issue do you think is the most important environmental issue in China?")
- `l7a`: most important
- `l7b`: 2nd most important

Values:
- Air Pollution - 1
- Fertilizer and pesticide pollution - 2
- Water scarcity - 3
- Water pollution - 4
- Nuclear waste - 5
- Disposal of domestic waste - 6
- Climate Change - 7
- Genetically modified food - 8
- Depletion of natural resources - 9
- None of the above - 10
- Cannot select - 98

Make label dictionary


```python
l7_labels = {'Air Pollution':1, 'Fertilizer and pesticide pollution':2, 'Water scarcity':3, 'Water pollution':4, 'Nuclear waste':5, 'Disposal of domestic waste':6, 'Climate Change':7, 'Genetically modified food':8, 'Depletion of natural resources':9, 'None of the above': 10, 'Cannot select':98}
```

Convert to dataframe


```python
l7_df = pd.DataFrame.from_dict(l7_labels, orient='index', columns=['l7a'])
```

**Attempting to put labels on histogram below, but can't**

Clean data, drop 10 & 98 (use the '~' to negate the .isin() function)
Cleaning both at the same time results in the same as doing it individually


```python
cgss_wq_l7=cgss_wq[~cgss_wq[['l7a','l7b']].isin([-3,-1,98])]
```


```python
cgss_wq_l7[['l7a','l7b']].describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>l7a</th>
      <th>l7b</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>3253.000000</td>
      <td>3298.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.554565</td>
      <td>3.990297</td>
    </tr>
    <tr>
      <th>std</th>
      <td>2.478664</td>
      <td>2.725078</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>4.000000</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>6.000000</td>
      <td>6.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>10.000000</td>
      <td>10.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
fig, ax = plt.subplots()
cgss_wq_l7.hist(['l7a','l7b'], ax=ax)
fig.savefig('outputs/l7_fig1.svg')
```

    <ipython-input-51-f38965d94704>:2: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared
      cgss_wq_l7.hist(['l7a','l7b'], ax=ax)




![png](output_115_1.png)
    



```python
l7_fig2 = sns.displot(
    data=cgss_wq_l7, 
    x='l7a', 
    # hue='l7b', 
    discrete = True, 
    # multiple='stack',
    kind = 'hist'
    )
l7_fig2.savefig('outputs/l7_fig2.svg')
```


​    
![png](output_116_0.png)
​    



```python
l7_fig3 = sns.displot(
    data=cgss_wq_l7, 
    x='l7b',
    # hue='l7b', 
    discrete = True, 
    # multiple='stack', 
    kind = 'hist'
    )
l7_fig3.savefig('outputs/l7_fig3.svg')
```


​    
![png](output_117_0.png)
​    


### Score vs knowledge `l2409`

---

## Normalize Data

---

## Multivariable statistical analysis


```python
ols_perception = smf.ols('l14d ~ score + C(a2) + a3a + a7a + C(a91)', data = cgss_wq).fit()
ols_perception.summary()
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>l14d</td>       <th>  R-squared:         </th> <td>   0.066</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.064</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   51.50</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 13 Mar 2021</td> <th>  Prob (F-statistic):</th> <td>9.21e-52</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>17:43:55</td>     <th>  Log-Likelihood:    </th> <td> -7618.3</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>  3671</td>      <th>  AIC:               </th> <td>1.525e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>  3665</td>      <th>  BIC:               </th> <td>1.529e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>     <td>    4.4156</td> <td>    1.174</td> <td>    3.761</td> <td> 0.000</td> <td>    2.114</td> <td>    6.717</td>
</tr>
<tr>
  <th>C(a2)[T.2]</th>    <td>    0.0559</td> <td>    0.065</td> <td>    0.865</td> <td> 0.387</td> <td>   -0.071</td> <td>    0.183</td>
</tr>
<tr>
  <th>C(a91)[T.1.0]</th> <td>    2.3748</td> <td>    0.591</td> <td>    4.018</td> <td> 0.000</td> <td>    1.216</td> <td>    3.533</td>
</tr>
<tr>
  <th>C(a91)[T.2.0]</th> <td>    2.0408</td> <td>    0.585</td> <td>    3.487</td> <td> 0.000</td> <td>    0.893</td> <td>    3.188</td>
</tr>
<tr>
  <th>score</th>         <td>   -0.0248</td> <td>    0.007</td> <td>   -3.446</td> <td> 0.001</td> <td>   -0.039</td> <td>   -0.011</td>
</tr>
<tr>
  <th>a3a</th>           <td>   -0.0014</td> <td>    0.001</td> <td>   -1.518</td> <td> 0.129</td> <td>   -0.003</td> <td>    0.000</td>
</tr>
<tr>
  <th>a7a</th>           <td>   -0.1223</td> <td>    0.012</td> <td>  -10.140</td> <td> 0.000</td> <td>   -0.146</td> <td>   -0.099</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>912.726</td> <th>  Durbin-Watson:     </th> <td>   1.849</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1900.260</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 1.460</td>  <th>  Prob(JB):          </th> <td>    0.00</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 4.974</td>  <th>  Cond. No.          </th> <td>1.87e+19</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.06e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular.




```python
ols_knowledge = smf.ols('l2409 ~ score + C(a2) + C(a91)', data = cgss_wq).fit()
ols_knowledge.summary()
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>l2409</td>      <th>  R-squared:         </th> <td>   0.008</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.008</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   10.30</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 13 Mar 2021</td> <th>  Prob (F-statistic):</th> <td>9.48e-07</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>17:43:55</td>     <th>  Log-Likelihood:    </th> <td> -9076.6</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>  3671</td>      <th>  AIC:               </th> <td>1.816e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>  3667</td>      <th>  BIC:               </th> <td>1.819e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>     <td>    3.9345</td> <td>    0.124</td> <td>   31.740</td> <td> 0.000</td> <td>    3.691</td> <td>    4.178</td>
</tr>
<tr>
  <th>C(a2)[T.2]</th>    <td>    0.3458</td> <td>    0.095</td> <td>    3.643</td> <td> 0.000</td> <td>    0.160</td> <td>    0.532</td>
</tr>
<tr>
  <th>C(a91)[T.1.0]</th> <td>    2.1612</td> <td>    0.076</td> <td>   28.491</td> <td> 0.000</td> <td>    2.013</td> <td>    2.310</td>
</tr>
<tr>
  <th>C(a91)[T.2.0]</th> <td>    1.7733</td> <td>    0.082</td> <td>   21.725</td> <td> 0.000</td> <td>    1.613</td> <td>    1.933</td>
</tr>
<tr>
  <th>score</th>         <td>    0.0185</td> <td>    0.011</td> <td>    1.747</td> <td> 0.081</td> <td>   -0.002</td> <td>    0.039</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>617.759</td> <th>  Durbin-Watson:     </th> <td>   1.683</td> 
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 991.087</td> 
</tr>
<tr>
  <th>Skew:</th>          <td>-1.273</td>  <th>  Prob(JB):          </th> <td>6.14e-216</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.017</td>  <th>  Cond. No.          </th> <td>1.50e+17</td> 
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.84e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular.



## NOTES
- Normalize variables (variance is different)
- Cannot use OLS, use LOGIT (logistic regression)

Things to change in the code
1. not use OLS for categorical output but use LOGIT (logitstic regression) to model categorical output
2. normalise continous variables as in the example notebook
3. Use the C(...) for categoricals 
4. To use to logit, you need a binary output:
4.a remove '8' answers to construct a first model and validate it
4.b. since most answers are '8' and you don't want to discard them, create a new logistic regression model with ternary output (this is possible)

R² shows model explains variation in dependent variable, while R is correlation between one variable and another
- With my correlation analysis, use R
- If I use OLS, use R²


```python
cgss_wq['score'].describe()
```




    count    11783.000000
    mean        16.488182
    std          4.554007
    min          6.901250
    25%         12.234444
    50%         16.965556
    75%         20.290000
    max         23.630000
    Name: score, dtype: float64



## Data overview

### Responses per province by type


```python
dem_dist = cgss_wq[demographic].dropna().groupby('s41').agg('count')
```


```python
env_dist = cgss_wq[environmental].dropna().groupby('s41').agg('count')
env_dist
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>province</th>
      <th>province_en</th>
      <th>score</th>
      <th>l1a</th>
      <th>l1b</th>
      <th>l6a</th>
      <th>l6b</th>
      <th>l7a</th>
      <th>l7b</th>
      <th>l8a</th>
      <th>l8b</th>
      <th>l14d</th>
      <th>l2409</th>
    </tr>
    <tr>
      <th>s41</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1.0</th>
      <td>183</td>
      <td>183</td>
      <td>183</td>
      <td>183</td>
      <td>183</td>
      <td>183</td>
      <td>183</td>
      <td>183</td>
      <td>183</td>
      <td>183</td>
      <td>183</td>
      <td>183</td>
      <td>183</td>
    </tr>
    <tr>
      <th>2.0</th>
      <td>103</td>
      <td>103</td>
      <td>103</td>
      <td>103</td>
      <td>103</td>
      <td>103</td>
      <td>103</td>
      <td>103</td>
      <td>103</td>
      <td>103</td>
      <td>103</td>
      <td>103</td>
      <td>103</td>
    </tr>
    <tr>
      <th>3.0</th>
      <td>28</td>
      <td>28</td>
      <td>28</td>
      <td>28</td>
      <td>28</td>
      <td>28</td>
      <td>28</td>
      <td>28</td>
      <td>28</td>
      <td>28</td>
      <td>28</td>
      <td>28</td>
      <td>28</td>
    </tr>
    <tr>
      <th>4.0</th>
      <td>173</td>
      <td>173</td>
      <td>173</td>
      <td>173</td>
      <td>173</td>
      <td>173</td>
      <td>173</td>
      <td>173</td>
      <td>173</td>
      <td>173</td>
      <td>173</td>
      <td>173</td>
      <td>173</td>
    </tr>
    <tr>
      <th>5.0</th>
      <td>164</td>
      <td>164</td>
      <td>164</td>
      <td>164</td>
      <td>164</td>
      <td>164</td>
      <td>164</td>
      <td>164</td>
      <td>164</td>
      <td>164</td>
      <td>164</td>
      <td>164</td>
      <td>164</td>
    </tr>
    <tr>
      <th>6.0</th>
      <td>179</td>
      <td>179</td>
      <td>179</td>
      <td>179</td>
      <td>179</td>
      <td>179</td>
      <td>179</td>
      <td>179</td>
      <td>179</td>
      <td>179</td>
      <td>179</td>
      <td>179</td>
      <td>179</td>
    </tr>
    <tr>
      <th>7.0</th>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
    </tr>
    <tr>
      <th>8.0</th>
      <td>27</td>
      <td>27</td>
      <td>27</td>
      <td>27</td>
      <td>27</td>
      <td>27</td>
      <td>27</td>
      <td>27</td>
      <td>27</td>
      <td>27</td>
      <td>27</td>
      <td>27</td>
      <td>27</td>
    </tr>
    <tr>
      <th>9.0</th>
      <td>126</td>
      <td>126</td>
      <td>126</td>
      <td>126</td>
      <td>126</td>
      <td>126</td>
      <td>126</td>
      <td>126</td>
      <td>126</td>
      <td>126</td>
      <td>126</td>
      <td>126</td>
      <td>126</td>
    </tr>
    <tr>
      <th>10.0</th>
      <td>153</td>
      <td>153</td>
      <td>153</td>
      <td>153</td>
      <td>153</td>
      <td>153</td>
      <td>153</td>
      <td>153</td>
      <td>153</td>
      <td>153</td>
      <td>153</td>
      <td>153</td>
      <td>153</td>
    </tr>
    <tr>
      <th>11.0</th>
      <td>96</td>
      <td>96</td>
      <td>96</td>
      <td>96</td>
      <td>96</td>
      <td>96</td>
      <td>96</td>
      <td>96</td>
      <td>96</td>
      <td>96</td>
      <td>96</td>
      <td>96</td>
      <td>96</td>
    </tr>
    <tr>
      <th>12.0</th>
      <td>190</td>
      <td>190</td>
      <td>190</td>
      <td>190</td>
      <td>190</td>
      <td>190</td>
      <td>190</td>
      <td>190</td>
      <td>190</td>
      <td>190</td>
      <td>190</td>
      <td>190</td>
      <td>190</td>
    </tr>
    <tr>
      <th>13.0</th>
      <td>122</td>
      <td>122</td>
      <td>122</td>
      <td>122</td>
      <td>122</td>
      <td>122</td>
      <td>122</td>
      <td>122</td>
      <td>122</td>
      <td>122</td>
      <td>122</td>
      <td>122</td>
      <td>122</td>
    </tr>
    <tr>
      <th>14.0</th>
      <td>18</td>
      <td>18</td>
      <td>18</td>
      <td>18</td>
      <td>18</td>
      <td>18</td>
      <td>18</td>
      <td>18</td>
      <td>18</td>
      <td>18</td>
      <td>18</td>
      <td>18</td>
      <td>18</td>
    </tr>
    <tr>
      <th>15.0</th>
      <td>158</td>
      <td>158</td>
      <td>158</td>
      <td>158</td>
      <td>158</td>
      <td>158</td>
      <td>158</td>
      <td>158</td>
      <td>158</td>
      <td>158</td>
      <td>158</td>
      <td>158</td>
      <td>158</td>
    </tr>
    <tr>
      <th>16.0</th>
      <td>165</td>
      <td>165</td>
      <td>165</td>
      <td>165</td>
      <td>165</td>
      <td>165</td>
      <td>165</td>
      <td>165</td>
      <td>165</td>
      <td>165</td>
      <td>165</td>
      <td>165</td>
      <td>165</td>
    </tr>
    <tr>
      <th>17.0</th>
      <td>91</td>
      <td>91</td>
      <td>91</td>
      <td>91</td>
      <td>91</td>
      <td>91</td>
      <td>91</td>
      <td>91</td>
      <td>91</td>
      <td>91</td>
      <td>91</td>
      <td>91</td>
      <td>91</td>
    </tr>
    <tr>
      <th>18.0</th>
      <td>157</td>
      <td>157</td>
      <td>157</td>
      <td>157</td>
      <td>157</td>
      <td>157</td>
      <td>157</td>
      <td>157</td>
      <td>157</td>
      <td>157</td>
      <td>157</td>
      <td>157</td>
      <td>157</td>
    </tr>
    <tr>
      <th>19.0</th>
      <td>196</td>
      <td>196</td>
      <td>196</td>
      <td>196</td>
      <td>196</td>
      <td>196</td>
      <td>196</td>
      <td>196</td>
      <td>196</td>
      <td>196</td>
      <td>196</td>
      <td>196</td>
      <td>196</td>
    </tr>
    <tr>
      <th>20.0</th>
      <td>29</td>
      <td>29</td>
      <td>29</td>
      <td>29</td>
      <td>29</td>
      <td>29</td>
      <td>29</td>
      <td>29</td>
      <td>29</td>
      <td>29</td>
      <td>29</td>
      <td>29</td>
      <td>29</td>
    </tr>
    <tr>
      <th>21.0</th>
      <td>209</td>
      <td>209</td>
      <td>209</td>
      <td>209</td>
      <td>209</td>
      <td>209</td>
      <td>209</td>
      <td>209</td>
      <td>209</td>
      <td>209</td>
      <td>209</td>
      <td>209</td>
      <td>209</td>
    </tr>
    <tr>
      <th>22.0</th>
      <td>155</td>
      <td>155</td>
      <td>155</td>
      <td>155</td>
      <td>155</td>
      <td>155</td>
      <td>155</td>
      <td>155</td>
      <td>155</td>
      <td>155</td>
      <td>155</td>
      <td>155</td>
      <td>155</td>
    </tr>
    <tr>
      <th>23.0</th>
      <td>52</td>
      <td>52</td>
      <td>52</td>
      <td>52</td>
      <td>52</td>
      <td>52</td>
      <td>52</td>
      <td>52</td>
      <td>52</td>
      <td>52</td>
      <td>52</td>
      <td>52</td>
      <td>52</td>
    </tr>
    <tr>
      <th>24.0</th>
      <td>101</td>
      <td>101</td>
      <td>101</td>
      <td>101</td>
      <td>101</td>
      <td>101</td>
      <td>101</td>
      <td>101</td>
      <td>101</td>
      <td>101</td>
      <td>101</td>
      <td>101</td>
      <td>101</td>
    </tr>
    <tr>
      <th>25.0</th>
      <td>19</td>
      <td>19</td>
      <td>19</td>
      <td>19</td>
      <td>19</td>
      <td>19</td>
      <td>19</td>
      <td>19</td>
      <td>19</td>
      <td>19</td>
      <td>19</td>
      <td>19</td>
      <td>19</td>
    </tr>
    <tr>
      <th>26.0</th>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
    </tr>
    <tr>
      <th>27.0</th>
      <td>119</td>
      <td>119</td>
      <td>119</td>
      <td>119</td>
      <td>119</td>
      <td>119</td>
      <td>119</td>
      <td>119</td>
      <td>119</td>
      <td>119</td>
      <td>119</td>
      <td>119</td>
      <td>119</td>
    </tr>
    <tr>
      <th>28.0</th>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
      <td>89</td>
    </tr>
    <tr>
      <th>29.0</th>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
      <td>120</td>
    </tr>
    <tr>
      <th>30.0</th>
      <td>26</td>
      <td>26</td>
      <td>26</td>
      <td>26</td>
      <td>26</td>
      <td>26</td>
      <td>26</td>
      <td>26</td>
      <td>26</td>
      <td>26</td>
      <td>26</td>
      <td>26</td>
      <td>26</td>
    </tr>
    <tr>
      <th>31.0</th>
      <td>215</td>
      <td>215</td>
      <td>215</td>
      <td>215</td>
      <td>215</td>
      <td>215</td>
      <td>215</td>
      <td>215</td>
      <td>215</td>
      <td>215</td>
      <td>215</td>
      <td>215</td>
      <td>215</td>
    </tr>
  </tbody>
</table>
</div>



---
### Education and Score


```python
cgss_wq_a7a = cgss_wq[~cgss_wq['a7a'].isin([-3,14])].dropna()
cgss_wq_a7a
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>score</th>
      <th>s41</th>
      <th>a2</th>
      <th>a3a</th>
      <th>a7a</th>
      <th>a8a</th>
      <th>a91</th>
      <th>l1a</th>
      <th>l1b</th>
      <th>l6a</th>
      <th>l6b</th>
      <th>l7a</th>
      <th>l7b</th>
      <th>l8a</th>
      <th>l8b</th>
      <th>l137</th>
      <th>l14d</th>
      <th>l15a</th>
      <th>l15b</th>
      <th>l16c</th>
      <th>l20e</th>
      <th>l2409</th>
      <th>province</th>
      <th>province_en</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>13.84</td>
      <td>28.0</td>
      <td>2</td>
      <td>1948</td>
      <td>1</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>8.0</td>
      <td>98.0</td>
      <td>98.0</td>
      <td>8.0</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>8.0</td>
      <td>8.0</td>
      <td>8.0</td>
      <td>4.0</td>
      <td>8.0</td>
      <td>重庆</td>
      <td>Chongqing</td>
    </tr>
    <tr>
      <th>5</th>
      <td>13.84</td>
      <td>28.0</td>
      <td>1</td>
      <td>1963</td>
      <td>4</td>
      <td>20000.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>6.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>6.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>重庆</td>
      <td>Chongqing</td>
    </tr>
    <tr>
      <th>6</th>
      <td>13.84</td>
      <td>28.0</td>
      <td>1</td>
      <td>1952</td>
      <td>3</td>
      <td>9999998.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>8.0</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>8.0</td>
      <td>重庆</td>
      <td>Chongqing</td>
    </tr>
    <tr>
      <th>8</th>
      <td>13.84</td>
      <td>28.0</td>
      <td>2</td>
      <td>1973</td>
      <td>3</td>
      <td>4200.0</td>
      <td>2.0</td>
      <td>98.0</td>
      <td>98.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>8.0</td>
      <td>重庆</td>
      <td>Chongqing</td>
    </tr>
    <tr>
      <th>11</th>
      <td>13.84</td>
      <td>28.0</td>
      <td>1</td>
      <td>1964</td>
      <td>4</td>
      <td>5000.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>6.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>7.0</td>
      <td>98.0</td>
      <td>8.0</td>
      <td>8.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>8.0</td>
      <td>8.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>重庆</td>
      <td>Chongqing</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>11770</th>
      <td>17.93</td>
      <td>8.0</td>
      <td>2</td>
      <td>1961</td>
      <td>1</td>
      <td>7500.0</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>6.0</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>宁夏</td>
      <td>Ningxia</td>
    </tr>
    <tr>
      <th>11773</th>
      <td>17.93</td>
      <td>8.0</td>
      <td>2</td>
      <td>1963</td>
      <td>3</td>
      <td>2600.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>6.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>6.0</td>
      <td>6.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>宁夏</td>
      <td>Ningxia</td>
    </tr>
    <tr>
      <th>11774</th>
      <td>17.93</td>
      <td>8.0</td>
      <td>1</td>
      <td>1956</td>
      <td>1</td>
      <td>4500.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>6.0</td>
      <td>6.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>宁夏</td>
      <td>Ningxia</td>
    </tr>
    <tr>
      <th>11775</th>
      <td>17.93</td>
      <td>8.0</td>
      <td>2</td>
      <td>1982</td>
      <td>3</td>
      <td>5000.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>宁夏</td>
      <td>Ningxia</td>
    </tr>
    <tr>
      <th>11780</th>
      <td>17.93</td>
      <td>8.0</td>
      <td>2</td>
      <td>1980</td>
      <td>4</td>
      <td>30000.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>宁夏</td>
      <td>Ningxia</td>
    </tr>
  </tbody>
</table>
<p>3664 rows × 24 columns</p>
</div>




```python
sns.lmplot(
    data=cgss_wq_a7a,
    x = 'a7a',
    y = 'score',
    x_estimator=np.mean,
    hue='a91'
    )
```




    <seaborn.axisgrid.FacetGrid at 0x7fb621cd19d0>




​    
![png](output_133_1.png)
​    



```python

```
